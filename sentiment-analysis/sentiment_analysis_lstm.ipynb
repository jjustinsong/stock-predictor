{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8raO1df1xCQs",
        "roEmbi97xK_y",
        "ADo5t8U9xUyI"
      ],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9O9S+PL9Ecpwu4gewlCK4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjustinsong/stock-predictor/blob/main/sentiment_analysis_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "8raO1df1xCQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d30prH491_s",
        "outputId": "590397da-3807-4497-e0d4-f199041e92b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rm7RS6Qa9x7C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "Nur3sR7IVC7q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwNxTs6W-TRT",
        "outputId": "e5e63f2f-3455-4895-992e-fa071e3d0efd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'stock_news.csv'\n",
        "df = pd.read_csv(filename)\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q9_aMuCl-Vxv",
        "outputId": "cdc3cda0-48ac-4836-cccc-49d34e8c823d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            headline     label\n",
              "0  Markets Close Mostly Lower Again; ROST, PANW R...  Negative\n",
              "1  Gap plummets on earnings miss, cuts full-year ...  Negative\n",
              "2  Billionaire Ken Fisher is Selling These 10 Stocks  Negative\n",
              "3          Corning net income drops 13%, shares fall  Negative\n",
              "4  Internet Explorer shutdown to cause Japan prob...  Negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d418378-042d-4dbc-b97d-48539437c725\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Markets Close Mostly Lower Again; ROST, PANW R...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gap plummets on earnings miss, cuts full-year ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Billionaire Ken Fisher is Selling These 10 Stocks</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Corning net income drops 13%, shares fall</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Internet Explorer shutdown to cause Japan prob...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d418378-042d-4dbc-b97d-48539437c725')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d418378-042d-4dbc-b97d-48539437c725 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d418378-042d-4dbc-b97d-48539437c725');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-392fcc5f-533a-4a4b-93e2-8496528167f2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-392fcc5f-533a-4a4b-93e2-8496528167f2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-392fcc5f-533a-4a4b-93e2-8496528167f2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26000,\n  \"fields\": [\n    {\n      \"column\": \"headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26000,\n        \"samples\": [\n          \"Phillips 66 (PSX) Stock Sinks As Market Gains: What You Should Know\",\n          \"5 Dirt Cheap Homebuilder Stocks in 2022\",\n          \"Royal Caribbean, Carnival, Norwegian Near Pre-Pandemic Crowds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Negative\",\n          \"Neutral\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "YFRfczcoxHwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1xRRb1SAjC9",
        "outputId": "ebaed8cc-29ab-44be-b77d-33c6dd7b39b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df['label'] = encoder.fit_transform(df['label'])\n",
        "\n",
        "X = df['headline'].values.reshape(-1, 1)\n",
        "y = df['label']\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "\n",
        "df_resampled = pd.DataFrame({'headline': X_resampled.flatten(), 'label': encoder.inverse_transform(y_resampled)})\n",
        "df_resampled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_uxmCwDbAhUQ",
        "outputId": "fec63d44-2257-4354-969b-a67d8c0bac4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            headline     label\n",
              "0  Markets Close Mostly Lower Again; ROST, PANW R...  Negative\n",
              "1  Gap plummets on earnings miss, cuts full-year ...  Negative\n",
              "2  Billionaire Ken Fisher is Selling These 10 Stocks  Negative\n",
              "3          Corning net income drops 13%, shares fall  Negative\n",
              "4  Internet Explorer shutdown to cause Japan prob...  Negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-156c7626-9174-41a8-92d1-49bffc3ebfbf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Markets Close Mostly Lower Again; ROST, PANW R...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gap plummets on earnings miss, cuts full-year ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Billionaire Ken Fisher is Selling These 10 Stocks</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Corning net income drops 13%, shares fall</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Internet Explorer shutdown to cause Japan prob...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-156c7626-9174-41a8-92d1-49bffc3ebfbf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-156c7626-9174-41a8-92d1-49bffc3ebfbf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-156c7626-9174-41a8-92d1-49bffc3ebfbf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-79a457de-0af6-4770-b737-88837e1f633d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79a457de-0af6-4770-b737-88837e1f633d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-79a457de-0af6-4770-b737-88837e1f633d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_resampled",
              "summary": "{\n  \"name\": \"df_resampled\",\n  \"rows\": 37344,\n  \"fields\": [\n    {\n      \"column\": \"headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26000,\n        \"samples\": [\n          \"Phillips 66 (PSX) Stock Sinks As Market Gains: What You Should Know\",\n          \"5 Dirt Cheap Homebuilder Stocks in 2022\",\n          \"Royal Caribbean, Carnival, Norwegian Near Pre-Pandemic Crowds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Negative\",\n          \"Neutral\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='label', data=df_resampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "5YHb0lRaBAbL",
        "outputId": "ac3b9f28-d47a-4409-b639-5424d9d68f17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='label', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df_resampled['headline'].values, df_resampled['label'].values\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
        "print(f'shape of train: {X_train.shape}, {y_train.shape}')\n",
        "print(f'shape of val: {X_val.shape}, {y_val.shape}')\n",
        "print(f'shape of test: {X_test.shape}, {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aHH8LlZ-sLb",
        "outputId": "08ac7203-8be5-4fd0-b3f6-aa4ae0692fc7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train: (22406,), (22406,)\n",
            "shape of val: (7469,), (7469,)\n",
            "shape of test: (7469,), (7469,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_sequence_lengths(texts):\n",
        "    lengths = []\n",
        "    for text in texts:\n",
        "        lengths.append(len(text.split()))\n",
        "    return lengths\n",
        "\n",
        "# Get sequence lengths for the training data\n",
        "sequence_lengths = get_sequence_lengths(X_train)\n",
        "\n",
        "# Plot the distribution of sequence lengths\n",
        "plt.hist(sequence_lengths, bins=50)\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Sequence Lengths')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Mean sequence length: {np.mean(sequence_lengths)}\")\n",
        "print(f\"Median sequence length: {np.median(sequence_lengths)}\")\n",
        "print(f\"Max sequence length: {np.max(sequence_lengths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "PifqtxYEfG4n",
        "outputId": "315d429e-faaa-4403-f0e8-387b9ed616eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean sequence length: 10.687672944746943\n",
            "Median sequence length: 10.0\n",
            "Max sequence length: 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSut3aC8EwmW",
        "outputId": "528809a8-7755-47b9-cbd8-87a6dccdb8ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tLE1VrgFYzy",
        "outputId": "ea3528eb-5dcb-40ed-deda-25dff6c9c6f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Negative', 'Negative', 'Positive', ..., 'Negative', 'Neutral',\n",
              "       'Neutral'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzWlbyM4Mo2N",
        "outputId": "53f99e39-7206-42f9-f379-f6a15908ba94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/410.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/410.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.15.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug.augmenter.word as naw"
      ],
      "metadata": {
        "id": "r3EfUmaQMwTW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext.vocab as vocab\n",
        "\n",
        "glove = vocab.GloVe(name='6B', dim=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH_4xx5_THAn",
        "outputId": "9ef912c5-a779-45d8-ad2e-a54b7c519786"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.38MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:18<00:00, 21288.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(glove.stoi) + 1, 100))\n",
        "for word, index in glove.stoi.items():\n",
        "    embedding_matrix[index] = glove.vectors[index]\n",
        "\n",
        "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "5D55ypSoTMsZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(embedding_matrix, 'glove_embeddings.pt')"
      ],
      "metadata": {
        "id": "-lPN_vbSdH2Z"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with one space\n",
        "    s = re.sub(r\"\\s+\", ' ', s)\n",
        "    # replace digits with no space\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s\n",
        "\n",
        "'''def tokenize(X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "    vocab = []\n",
        "\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    for text in X_train:\n",
        "        for word in text.lower().split():\n",
        "            word = preprocess(word)\n",
        "            if word not in stop_words and word != '':\n",
        "                vocab.append(word)\n",
        "\n",
        "    corpus = Counter(vocab)\n",
        "    # sorting on the basis of most common words\n",
        "    corpus_ = sorted(corpus, key=corpus.get, reverse=True)[:1000]\n",
        "    # creating a dict\n",
        "    onehot_dict = {w: i + 1 for i, w in enumerate(corpus_)}\n",
        "\n",
        "    # tokenize\n",
        "    final_train, final_val, final_test = [], [], []\n",
        "    for text in X_train:\n",
        "        temp = []\n",
        "        for word in text.lower().split():\n",
        "            word = preprocess(word)\n",
        "            if word in onehot_dict.keys():\n",
        "                temp.append(onehot_dict[word])\n",
        "        final_train.append(temp)\n",
        "    for text in X_val:\n",
        "        temp = []\n",
        "        for word in text.lower().split():\n",
        "            word = preprocess(word)\n",
        "            if word in onehot_dict.keys():\n",
        "                temp.append(onehot_dict[word])\n",
        "        final_val.append(temp)\n",
        "    for text in X_test:\n",
        "        temp = []\n",
        "        for word in text.lower().split():\n",
        "            word = preprocess(word)\n",
        "            if word in onehot_dict.keys():\n",
        "                temp.append(onehot_dict[word])\n",
        "        final_test.append(temp)\n",
        "\n",
        "    max_length = max(len(seq) for seq in final_train + final_val + final_test)\n",
        "    final_train = [seq + [0] * (max_length - len(seq)) for seq in final_train]\n",
        "    final_val = [seq + [0] * (max_length - len(seq)) for seq in final_val]\n",
        "    final_test = [seq + [0] * (max_length - len(seq)) for seq in final_test]\n",
        "\n",
        "    label_mapping = {'Positive': 2, 'Neutral': 1, 'Negative': 0}\n",
        "    encoded_train = [label_mapping[i] for i in y_train]\n",
        "    encoded_val = [label_mapping[i] for i in y_val]\n",
        "    encoded_test = [label_mapping[i] for i in y_test]\n",
        "    return np.array(final_train), np.array(encoded_train), np.array(final_val), np.array(encoded_val), np.array(final_test), np.array(encoded_test), onehot_dict'''\n",
        "\n",
        "def tokenize_glove(X_train, X_val, X_test, y_train, y_val, y_test, max_length):\n",
        "    def get_indices(texts):\n",
        "        indices = []\n",
        "        for text in texts:\n",
        "            temp = []\n",
        "            for word in text.lower().split()[:max_length]:\n",
        "                word = preprocess(word)\n",
        "                if word in glove.stoi:\n",
        "                    temp.append(glove.stoi[word])\n",
        "                else:\n",
        "                    temp.append(0)\n",
        "            if len(temp) < max_length:\n",
        "                temp.extend([0] * (max_length - len(temp)))\n",
        "            indices.append(temp)\n",
        "        return indices\n",
        "\n",
        "    final_train = get_indices(X_train)\n",
        "    final_val = get_indices(X_val)\n",
        "    final_test = get_indices(X_test)\n",
        "\n",
        "    label_mapping = {'Positive': 2, 'Neutral': 1, 'Negative': 0}\n",
        "    encoded_train = [label_mapping[i] for i in y_train]\n",
        "    encoded_val = [label_mapping[i] for i in y_val]\n",
        "    encoded_test = [label_mapping[i] for i in y_test]\n",
        "\n",
        "    return np.array(final_train), np.array(encoded_train), np.array(final_val), np.array(encoded_val), np.array(final_test), np.array(encoded_test)"
      ],
      "metadata": {
        "id": "RrCrcTF-_kq1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ettSysEHJ1DW",
        "outputId": "a46b2102-f74b-46c7-822d-54c0b0cb9101"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import random\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "try:\n",
        "    spacy.require_gpu()\n",
        "except:\n",
        "    print('GPU not available')\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "synonym_cache = {}\n",
        "\n",
        "def identify_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = {ent.text for ent in doc.ents}\n",
        "    return entities\n",
        "\n",
        "def get_synonyms(word, pos_tag):\n",
        "    if word in synonym_cache:\n",
        "        return synonym_cache[word]\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        if syn.pos() == pos_tag:\n",
        "            for lemma in syn.lemmas():\n",
        "                synonym = lemma.name().replace('_', ' ')\n",
        "                if synonym != word and synonym not in stop_words:\n",
        "                    synonyms.add(synonym)\n",
        "    synonym_cache[word] = list(synonyms)\n",
        "    return synonym_cache[word]\n",
        "\n",
        "def replace_word_with_synonym(words, entities):\n",
        "    new_words = words[:]\n",
        "    pos_tags = nlp(' '.join(new_words))\n",
        "    attempts = 0\n",
        "    while attempts < 10:\n",
        "        random_idx = random.randint(0, len(new_words) - 1)\n",
        "        random_word = new_words[random_idx]\n",
        "        if random_word in entities or random_word.lower() in stop_words:\n",
        "            attempts += 1\n",
        "            continue\n",
        "        pos_tag = pos_tags[random_idx].pos_\n",
        "        wn_pos = {\n",
        "            'NOUN': 'n',\n",
        "            'VERB': 'v',\n",
        "            'ADJ': 'a',\n",
        "            'ADV': 'r'\n",
        "        }.get(pos_tag, None)\n",
        "        if wn_pos is None:\n",
        "            attempts += 1\n",
        "            continue\n",
        "        synonyms = get_synonyms(random_word, wn_pos)\n",
        "        if synonyms:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words[random_idx] = synonym\n",
        "            break\n",
        "        attempts += 1\n",
        "    return new_words\n",
        "\n",
        "def augment_text_simple(text):\n",
        "    entities = identify_entities(text)\n",
        "    words = text.split()\n",
        "    if len(words) > 1:\n",
        "        words = replace_word_with_synonym(words, entities)\n",
        "    augmented_text = ' '.join(words)\n",
        "    return augmented_text"
      ],
      "metadata": {
        "id": "Pd9qnKicuIhz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_augmented = [augment_text_simple(text) for text in X_train]\n",
        "\n",
        "X_train_augmented = np.array(X_train_augmented)"
      ],
      "metadata": {
        "id": "lLA4cW2iNqvH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20, 30):\n",
        "    print(f\"Original: {X_train[i]}\")\n",
        "    print(f\"Augmented: {X_train_augmented[i]}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UykQ4fRcU6uR",
        "outputId": "4b4c7563-9cb0-4b18-cf32-9813c5352e17"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: Nancy Altobello Appointed to Board of Directors of Amphenol Corporation\n",
            "Augmented: Nancy Altobello nominate to Board of Directors of Amphenol Corporation\n",
            "---\n",
            "Original: Regions Financial Scheduled to Participate in Deutsche Bank Global Financial Services Conference\n",
            "Augmented: Regions Financial schedule to Participate in Deutsche Bank Global Financial Services Conference\n",
            "---\n",
            "Original: Company News for Jun 7, 2022\n",
            "Augmented: Company News for Jun 7, 2022\n",
            "---\n",
            "Original: Economist: 'Consumer is still out there spending' despite slowing growth, inflation\n",
            "Augmented: Economist: 'Consumer is stillness out there spending' despite slowing growth, inflation\n",
            "---\n",
            "Original: IFF Appoints Nicolas Mirzayantz President of IFFs Nourish Division\n",
            "Augmented: IFF Appoints Nicolas Mirzayantz President of IFFs Nourish Division\n",
            "---\n",
            "Original: Global gas prices: These countries are facing more pain than the U.S.\n",
            "Augmented: Global gas prices: These countries are facing more pain than the U.S.\n",
            "---\n",
            "Original: NortonLifeLock Receives Antitrust Clearance in Spain for Merger with Avast plc\n",
            "Augmented: NortonLifeLock Receives Antitrust Clearance in Spain for Merger with Avast plc\n",
            "---\n",
            "Original: Rockwell Automation stock suffers biggest selloff in more than 2 years as strong demand loses to supply chain, inflation pressures\n",
            "Augmented: Rockwell Automation stock tolerate biggest selloff in more than 2 years as strong demand loses to supply chain, inflation pressures\n",
            "---\n",
            "Original: Electronic Arts In Trouble As Activists Bring Gambling Charges Against 'FIFA: Ultimate Team'\n",
            "Augmented: Electronic Arts In Trouble As Activists Bring Gambling Charges Against 'FIFA: ultimate Team'\n",
            "---\n",
            "Original: Comerica Bank Announces Additional Retail Banking Transformation Changes\n",
            "Augmented: Comerica Bank announce Additional Retail Banking Transformation Changes\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_val, y_val, X_test, y_test = tokenize_glove(X_train_augmented, X_val, X_test, y_train, y_val, y_test, 15)"
      ],
      "metadata": {
        "id": "XnHZxXkWDYqA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnQ8QBb3Emsl",
        "outputId": "75d8982a-7a83-4901-a4ca-4de0dba1564f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,  2250,  9912,  1025,     0, 29019,    25,  3292,     5,\n",
              "        4361, 14672,  1932,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "val_data = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=64)\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size=64)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=64)"
      ],
      "metadata": {
        "id": "ZuuESXlPHfcT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "roEmbi97xK_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentAnalysisLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super(SentimentAnalysisLSTM, self).__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        h0 = torch.zeros((self.n_layers, batch_size, self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.n_layers, batch_size, self.hidden_dim)).to(device)\n",
        "        hidden = (h0, c0)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "D-5Vc9S9IpwD"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPSzHRNnUJ0E",
        "outputId": "0719e89f-359d-4b98-c951-dfed0dcbcab2"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[311, 402,   0, ...,   0,   0,   0],\n",
              "       [ 18, 422,   1, ...,   0,   0,   0],\n",
              "       [372,  56,   0, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [881, 196, 164, ...,   0,   0,   0],\n",
              "       [875,  37, 406, ...,   0,   0,   0],\n",
              "       [ 44,   2, 278, ...,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY7ERT6fUVHC",
        "outputId": "6e9cd396-f7f9-4ab9-9cec-93573a5b8faa"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22406,)"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentAnalysisLSTM(vocab_size=len(vocab)+1, embedding_dim=64, hidden_dim=256, output_dim=3, n_layers=2, dropout=0.5)\n",
        "model.to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "733ccUoBJ-8A",
        "outputId": "918bb7a6-cae4-4b8f-a57a-cef83481f48d"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentAnalysisLSTM(\n",
            "  (embedding): Embedding(1001, 64)\n",
            "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Training"
      ],
      "metadata": {
        "id": "ADo5t8U9xUyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0)"
      ],
      "metadata": {
        "id": "eHJGOvJOLwSE"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(pred, label):\n",
        "    pred = pred.argmax(dim=1, keepdim=True)\n",
        "    correct = pred.eq(label.view_as(pred)).sum().item()\n",
        "    return correct"
      ],
      "metadata": {
        "id": "-9ujLWfAMCp1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "HfJ7gygyqAeV"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, loss_function, optimizer, epochs):\n",
        "    '''\n",
        "    Trains the LSTM model on the training data.\n",
        "    '''\n",
        "\n",
        "    #scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-5, max_lr=0.00025, step_size_up=15, mode='triangular', cycle_momentum=False)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_losses = []\n",
        "        train_acc = 0.0\n",
        "\n",
        "        # Sets model to training mode, enabling dropout and batch normalization\n",
        "        model.train()\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            batch_size = inputs.size(0)\n",
        "            h = model.init_hidden(batch_size=batch_size)\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            h = tuple([each.data for each in h])\n",
        "            # Reset gradients to prevent accumulation across batches\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs, h = model(inputs, h)\n",
        "\n",
        "            outputs = outputs.view(batch_size, -1).float()\n",
        "            outputs = F.softmax(outputs, dim=1)\n",
        "            targets = targets.long().to(device)\n",
        "\n",
        "            # Calculates loss by comparing outputs to targets\n",
        "            loss = loss_function(outputs, targets)\n",
        "\n",
        "            # Calculates gradient of loss to adjust weights efficiently\n",
        "            loss.backward()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            acc = accuracy(outputs, targets)\n",
        "            train_acc += acc\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "\n",
        "            # Updates weights based on calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            #scheduler.step()\n",
        "\n",
        "        # Validation loop\n",
        "\n",
        "        val_losses = []\n",
        "        val_acc = 0.0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                val_batch_size = inputs.size(0)\n",
        "                val_h = model.init_hidden(batch_size=val_batch_size)\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "                outputs, val_h = model(inputs, val_h)\n",
        "                outputs = outputs.view(val_batch_size, -1).float()\n",
        "                outputs = F.softmax(outputs, dim=1)\n",
        "                targets = targets.long().to(device)\n",
        "                val_losses.append(loss_function(outputs, targets).item())\n",
        "                acc = accuracy(outputs, targets)\n",
        "                val_acc += acc\n",
        "\n",
        "\n",
        "        train_loss = np.mean(train_losses)\n",
        "        val_loss = np.mean(val_losses)\n",
        "        train_acc = train_acc/len(train_loader.dataset)\n",
        "        val_acc = val_acc/len(val_loader.dataset)\n",
        "\n",
        "\n",
        "        #current_lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {train_loss}, Val loss: {val_loss}, Train Acc: {train_acc}, Val Acc: {val_acc}')"
      ],
      "metadata": {
        "id": "V4X8b_SkMJhF"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z9YE1EAQxRJ",
        "outputId": "27a44b49-8dba-47d2-8e6e-aef8ad2cda2a"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0986218224903117, Val loss: 1.0986792175178854, Train Acc: 0.3341961974471124, Val Acc: 0.3266836256526978\n",
            "Epoch 2, Loss: 1.09863344794325, Val loss: 1.0986849487337291, Train Acc: 0.33330357939837546, Val Acc: 0.3266836256526978\n",
            "Epoch 3, Loss: 1.0986064607940849, Val loss: 1.0986839838517017, Train Acc: 0.33549049361778094, Val Acc: 0.3266836256526978\n",
            "Epoch 4, Loss: 1.0985779378488871, Val loss: 1.098680887466822, Train Acc: 0.33607069534946, Val Acc: 0.3266836256526978\n",
            "Epoch 5, Loss: 1.0986494980646335, Val loss: 1.0986859309367645, Train Acc: 0.33433009015442294, Val Acc: 0.3266836256526978\n",
            "Epoch 6, Loss: 1.098558235032606, Val loss: 1.098682977195479, Train Acc: 0.3364723734713916, Val Acc: 0.3266836256526978\n",
            "Epoch 7, Loss: 1.0986194196250025, Val loss: 1.0986902479432588, Train Acc: 0.3339284120324913, Val Acc: 0.3266836256526978\n",
            "Epoch 8, Loss: 1.0986228991098215, Val loss: 1.098688028816484, Train Acc: 0.3333482103008123, Val Acc: 0.3266836256526978\n",
            "Epoch 9, Loss: 1.0986542185487231, Val loss: 1.0986870741232848, Train Acc: 0.33557975542265467, Val Acc: 0.3266836256526978\n",
            "Epoch 10, Loss: 1.0986025941337956, Val loss: 1.0986915103390686, Train Acc: 0.33656163527626526, Val Acc: 0.3266836256526978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "2Ny90JuHQ-NC"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwqEfbVVeUJ-",
        "outputId": "3386b360-8238-479e-c434-0f5558176ff0"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoqsJ-Oze1_m",
        "outputId": "79855ee9-c2c4-4acc-d216-d87a8ab1de10"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0987313479779452, Val loss: 1.0987856296392589, Train Acc: 0.3325894849593859, Val Acc: 0.33431516936671574, LR: 0.00015400000000000036\n",
            "Epoch 2, Loss: 1.0988063034508642, Val loss: 1.0986635297791572, Train Acc: 0.33142908149602784, Val Acc: 0.3266836256526978, LR: 0.00020199999999999933\n",
            "Epoch 3, Loss: 1.0987573209990802, Val loss: 1.098715950281192, Train Acc: 0.33192002142283317, Val Acc: 0.3266836256526978, LR: 5.8000000000000685e-05\n",
            "Epoch 4, Loss: 1.0987163259093238, Val loss: 1.0988559824788673, Train Acc: 0.33357136481299654, Val Acc: 0.3266836256526978, LR: 0.00010600000000000137\n",
            "Epoch 5, Loss: 1.0987369188895593, Val loss: 1.0987588258890004, Train Acc: 0.3354458627153441, Val Acc: 0.3266836256526978, LR: 0.00025\n",
            "Epoch 6, Loss: 1.0987163687024022, Val loss: 1.0987153756312835, Train Acc: 0.3292421672766223, Val Acc: 0.3266836256526978, LR: 0.00010600000000000137\n",
            "Epoch 7, Loss: 1.0987099293630007, Val loss: 1.0987757403626401, Train Acc: 0.32973310720342763, Val Acc: 0.3266836256526978, LR: 5.799999999999727e-05\n",
            "Epoch 8, Loss: 1.0986756232389359, Val loss: 1.0987708517628858, Train Acc: 0.33053646344729093, Val Acc: 0.3266836256526978, LR: 0.00020200000000000274\n",
            "Epoch 9, Loss: 1.0986994671346115, Val loss: 1.0987265446247199, Train Acc: 0.33557975542265467, Val Acc: 0.3266836256526978, LR: 0.00015399999999999865\n",
            "Epoch 10, Loss: 1.0987350876175102, Val loss: 1.0986800540206778, Train Acc: 0.33464250647148086, Val Acc: 0.3266836256526978, LR: 1e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "_iEqDoFXe5ss"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYx1YW-bfRgk",
        "outputId": "18dfdd8a-9276-42a4-8bee-396e338a68e0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbq1__iLfSMg",
        "outputId": "fc9e5d32-5c99-4f78-ed15-0b7cd117b0f0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7491782722561574, Val loss: 0.8358887492591499, Train Acc: 0.8010354369365349, Val Acc: 0.7141518275538894\n",
            "Epoch 2, Loss: 0.743416719786961, Val loss: 0.8374442414850252, Train Acc: 0.805677050789967, Val Acc: 0.7097335654036685\n",
            "Epoch 3, Loss: 0.7430100861017442, Val loss: 0.8424490988254547, Train Acc: 0.8065250379362671, Val Acc: 0.7045119828624983\n",
            "Epoch 4, Loss: 0.7390779163289852, Val loss: 0.8325231592369895, Train Acc: 0.811523699009194, Val Acc: 0.7158923550676128\n",
            "Epoch 5, Loss: 0.7337302023946134, Val loss: 0.8387565921005021, Train Acc: 0.8159867892528787, Val Acc: 0.7086624715490695\n",
            "Epoch 6, Loss: 0.7332295012712139, Val loss: 0.8312535390385196, Train Acc: 0.8168347763991788, Val Acc: 0.7158923550676128\n",
            "Epoch 7, Loss: 0.7264537899708442, Val loss: 0.8387917287838764, Train Acc: 0.8233955190573954, Val Acc: 0.710269112330968\n",
            "Epoch 8, Loss: 0.723689640979794, Val loss: 0.8418867193226122, Train Acc: 0.8260287423011693, Val Acc: 0.7075913776944704\n",
            "Epoch 9, Loss: 0.7214630508899008, Val loss: 0.8277999682304187, Train Acc: 0.8280817638132643, Val Acc: 0.7220511447315571\n",
            "Epoch 10, Loss: 0.7161493098174624, Val loss: 0.8316702580350077, Train Acc: 0.834285459251986, Val Acc: 0.715624581603963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "AB57fp-nfS_h"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn-5HUy3gTWw",
        "outputId": "b634f1fc-9970-495c-c250-ab0274b6e62f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BagWNChgUKR",
        "outputId": "a1f4946e-151f-4f1c-bad4-8b366dff1348"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7178106369203575, Val loss: 0.8288966053062015, Train Acc: 0.8320539141301437, Val Acc: 0.7181684295086357\n",
            "Epoch 2, Loss: 0.7175986544892043, Val loss: 0.8319862884843451, Train Acc: 0.8321878068374543, Val Acc: 0.7173651091176865\n",
            "Epoch 3, Loss: 0.7165570949521792, Val loss: 0.8257943452932895, Train Acc: 0.833437472105686, Val Acc: 0.7239255589771054\n",
            "Epoch 4, Loss: 0.7103113857723676, Val loss: 0.8286994091975384, Train Acc: 0.8395965366419709, Val Acc: 0.7187039764359352\n",
            "Epoch 5, Loss: 0.713575676997616, Val loss: 0.8242432956512158, Train Acc: 0.8370525752030706, Val Acc: 0.7236577855134556\n",
            "Epoch 6, Loss: 0.7116063777118199, Val loss: 0.8259340196083753, Train Acc: 0.838123716861555, Val Acc: 0.7223189181952069\n",
            "Epoch 7, Loss: 0.7077249269002515, Val loss: 0.8179074966499948, Train Acc: 0.8422743907881818, Val Acc: 0.7314232159592984\n",
            "Epoch 8, Loss: 0.7054683053374461, Val loss: 0.8227668559958792, Train Acc: 0.8442381504954031, Val Acc: 0.726469406881778\n",
            "Epoch 9, Loss: 0.7032426361860801, Val loss: 0.8275389732458652, Train Acc: 0.8470052664464875, Val Acc: 0.7201767304860088\n",
            "Epoch 10, Loss: 0.7033431053841845, Val loss: 0.8260615457836379, Train Acc: 0.8470052664464875, Val Acc: 0.722185031463382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "ZfadLhKagVde"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdXJTx5xg1-k",
        "outputId": "2cb417b5-2313-44e3-f78b-d6a4352e4aa1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTby3OEwg2tO",
        "outputId": "30a540ec-b8a0-4697-8b2e-bb2f4522e10e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7039631110285216, Val loss: 0.8309391966232886, Train Acc: 0.8465143265196823, Val Acc: 0.7172312223858616\n",
            "Epoch 2, Loss: 0.7040423974501083, Val loss: 0.8250113188201545, Train Acc: 0.8464696956172454, Val Acc: 0.7239255589771054\n",
            "Epoch 3, Loss: 0.7013117140438009, Val loss: 0.8313611921591636, Train Acc: 0.8485673480317772, Val Acc: 0.716695675458562\n",
            "Epoch 4, Loss: 0.6987958802136137, Val loss: 0.8268436050822592, Train Acc: 0.8517807730072302, Val Acc: 0.7208461641451333\n",
            "Epoch 5, Loss: 0.6990656876530015, Val loss: 0.8188649235118148, Train Acc: 0.851245202177988, Val Acc: 0.7310215557638238\n",
            "Epoch 6, Loss: 0.696675771483341, Val loss: 0.8310383802805191, Train Acc: 0.8530304382754619, Val Acc: 0.7187039764359352\n",
            "Epoch 7, Loss: 0.6949750208820664, Val loss: 0.8213736921803564, Train Acc: 0.8554405070070517, Val Acc: 0.7278082742000268\n",
            "Epoch 8, Loss: 0.6950833248173799, Val loss: 0.8242296846503885, Train Acc: 0.8547710434704989, Val Acc: 0.725398313027179\n",
            "Epoch 9, Loss: 0.6943686383426955, Val loss: 0.8247219474397154, Train Acc: 0.8561546014460413, Val Acc: 0.7239255589771054\n",
            "Epoch 10, Loss: 0.6930382474512925, Val loss: 0.827287404710411, Train Acc: 0.8572257431045256, Val Acc: 0.7208461641451333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "lONaLo0gg3oI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUcyAQLnhUbx",
        "outputId": "3b3fa21a-eb8e-40ed-a12e-0d466abb1859"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL0xybpwhVob",
        "outputId": "3956cd4e-4024-4969-fb6c-85981c6d0f92"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6911698418234963, Val loss: 0.8232340985893184, Train Acc: 0.8589663482995626, Val Acc: 0.7252644262953541\n",
            "Epoch 2, Loss: 0.6900263870833774, Val loss: 0.8222790770551078, Train Acc: 0.8609747389092207, Val Acc: 0.7276743874682019\n",
            "Epoch 3, Loss: 0.6916482366950978, Val loss: 0.8230403353515853, Train Acc: 0.8586539319825047, Val Acc: 0.727540500736377\n",
            "Epoch 4, Loss: 0.690792988353381, Val loss: 0.8207869743689512, Train Acc: 0.8592787646166206, Val Acc: 0.7276743874682019\n",
            "Epoch 5, Loss: 0.6894372040977151, Val loss: 0.8208236350462987, Train Acc: 0.8614210479335892, Val Acc: 0.7279421609318516\n",
            "Epoch 6, Loss: 0.6894387925912582, Val loss: 0.8267062752165346, Train Acc: 0.8615103097384629, Val Acc: 0.7239255589771054\n",
            "Epoch 7, Loss: 0.6922258097843165, Val loss: 0.8258385074953748, Train Acc: 0.8578505757386414, Val Acc: 0.72432721917258\n",
            "Epoch 8, Loss: 0.6902653683779413, Val loss: 0.8189084585915264, Train Acc: 0.8602606444702312, Val Acc: 0.7306198955683492\n",
            "Epoch 9, Loss: 0.6864239468043949, Val loss: 0.8343456682995853, Train Acc: 0.8640989020798, Val Acc: 0.7152229214084884\n",
            "Epoch 10, Loss: 0.6900009041846054, Val loss: 0.8215782053959675, Train Acc: 0.8604391680799786, Val Acc: 0.7280760476636765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "b1HsOWGMhWXL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk_w71SvjaXw",
        "outputId": "4d43f8bc-f92d-4bcc-dfb3-e99c1fd37695"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MCE8yCNjh3j",
        "outputId": "71f99e01-259b-47f6-d874-1b70f68a32d8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6862240272139687, Val loss: 0.8205226776946304, Train Acc: 0.8637864857627421, Val Acc: 0.7282099343955014\n",
            "Epoch 2, Loss: 0.6812049879157084, Val loss: 0.8175443757293571, Train Acc: 0.8698562884941533, Val Acc: 0.7324943098138974\n",
            "Epoch 3, Loss: 0.679955709082594, Val loss: 0.8206393191447625, Train Acc: 0.8706150138355797, Val Acc: 0.7292810282501004\n",
            "Epoch 4, Loss: 0.6798835359354332, Val loss: 0.8138096630573273, Train Acc: 0.8707935374453272, Val Acc: 0.7357075913776945\n",
            "Epoch 5, Loss: 0.67991999357131, Val loss: 0.8158234233020717, Train Acc: 0.8706596447380166, Val Acc: 0.733967063863971\n",
            "Epoch 6, Loss: 0.6775253411706607, Val loss: 0.8149887522061666, Train Acc: 0.8728019280549852, Val Acc: 0.7347703842549204\n",
            "Epoch 7, Loss: 0.6781892607283491, Val loss: 0.8154489894707998, Train Acc: 0.8721324645184325, Val Acc: 0.7345026107912705\n",
            "Epoch 8, Loss: 0.6769750395446973, Val loss: 0.8118772542374766, Train Acc: 0.8738284388110328, Val Acc: 0.7378497790868925\n",
            "Epoch 9, Loss: 0.6754070564615573, Val loss: 0.8114185519198067, Train Acc: 0.8751673658841381, Val Acc: 0.7386530994778417\n",
            "Epoch 10, Loss: 0.6769065268539668, Val loss: 0.8132202607444209, Train Acc: 0.8736945461037222, Val Acc: 0.7365109117686437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "VYhhl7qFjipj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECT4j-qDkp4g",
        "outputId": "654d6eb7-e3fa-45ab-f0c9-97f54b3d0a99"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p95r3HXalFb3",
        "outputId": "6aa965b5-327c-467a-917b-70f78f9e493b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6750600316725172, Val loss: 0.8140009970237048, Train Acc: 0.8758814603231277, Val Acc: 0.7365109117686437\n",
            "Epoch 2, Loss: 0.6751175196296648, Val loss: 0.8130250995994633, Train Acc: 0.8754797822011962, Val Acc: 0.7365109117686437\n",
            "Epoch 3, Loss: 0.6752146982432432, Val loss: 0.8134269383218553, Train Acc: 0.8751673658841381, Val Acc: 0.7365109117686437\n",
            "Epoch 4, Loss: 0.6753531742878205, Val loss: 0.8137302880103772, Train Acc: 0.8757029367133804, Val Acc: 0.7365109117686437\n",
            "Epoch 5, Loss: 0.6748860527717438, Val loss: 0.8134092795543182, Train Acc: 0.8755244131036329, Val Acc: 0.7365109117686437\n",
            "Epoch 6, Loss: 0.6751449736480876, Val loss: 0.8138058419920441, Train Acc: 0.8753905203963224, Val Acc: 0.7365109117686437\n",
            "Epoch 7, Loss: 0.6749955297536755, Val loss: 0.8130250751462758, Train Acc: 0.8760599839328751, Val Acc: 0.7365109117686437\n",
            "Epoch 8, Loss: 0.6750025256894284, Val loss: 0.8136106271010178, Train Acc: 0.8759260912255645, Val Acc: 0.7365109117686437\n",
            "Epoch 9, Loss: 0.6753484047258461, Val loss: 0.8138701523471082, Train Acc: 0.8753012585914487, Val Acc: 0.7365109117686437\n",
            "Epoch 10, Loss: 0.6751507740047961, Val loss: 0.8138058139727666, Train Acc: 0.8754351512987593, Val Acc: 0.7365109117686437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "d4BDPTiylGNi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCZHJyEolz3A",
        "outputId": "e03d27ca-0636-4a3b-cb36-210cafaeecaa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5qQM8MGl48Y",
        "outputId": "ce1ddf0c-2dd7-4e29-a55f-d4ef45eafae8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6754496129025066, Val loss: 0.811027406117855, Train Acc: 0.8753905203963224, Val Acc: 0.7402597402597403\n",
            "Epoch 2, Loss: 0.6742399809363905, Val loss: 0.8140066360306536, Train Acc: 0.876372400249933, Val Acc: 0.7366447985004686\n",
            "Epoch 3, Loss: 0.6728359018684964, Val loss: 0.8102657909576709, Train Acc: 0.8779344818352227, Val Acc: 0.7399919667960905\n",
            "Epoch 4, Loss: 0.6718934853474866, Val loss: 0.8107027666181581, Train Acc: 0.8789163616888334, Val Acc: 0.7390547596733164\n",
            "Epoch 5, Loss: 0.6710632547162229, Val loss: 0.8133207243731898, Train Acc: 0.8795411943229492, Val Acc: 0.7353059311822199\n",
            "Epoch 6, Loss: 0.6711473663931397, Val loss: 0.8162199635790963, Train Acc: 0.8794073016156386, Val Acc: 0.7330298567411969\n",
            "Epoch 7, Loss: 0.6707882201790639, Val loss: 0.8099408840012347, Train Acc: 0.8796750870302598, Val Acc: 0.7401258535279154\n",
            "Epoch 8, Loss: 0.6695789542585909, Val loss: 0.810437191500623, Train Acc: 0.8809693832009283, Val Acc: 0.7395903066006159\n",
            "Epoch 9, Loss: 0.6695091205724806, Val loss: 0.813246592751935, Train Acc: 0.8813264304204231, Val Acc: 0.7367786852322935\n",
            "Epoch 10, Loss: 0.6697836359285254, Val loss: 0.8169490473392682, Train Acc: 0.8813710613228599, Val Acc: 0.7331637434730218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "G9AQlLdHm1lK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhjhT54dm3p-",
        "outputId": "6e8e4116-811e-49c6-c870-65864aa26a03"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(model, test_loader):\n",
        "    test_acc = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            test_batch_size = inputs.size(0)\n",
        "            test_h = model.init_hidden(batch_size=test_batch_size)\n",
        "            test_h = tuple([each.data for each in test_h])\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs, test_h = model(inputs, test_h)\n",
        "            outputs = outputs.view(test_batch_size, -1).float()\n",
        "            outputs = F.softmax(outputs, dim=1)\n",
        "            targets = targets.long().to(device)\n",
        "            acc = accuracy(outputs, targets)\n",
        "            test_acc += acc\n",
        "\n",
        "    test_acc = test_acc/len(test_loader.dataset)\n",
        "    return test_acc"
      ],
      "metadata": {
        "id": "tAo0zhoJl59f"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = test_accuracy(model, test_loader)\n",
        "print(f'Test accuracy: {a}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyLGeTvDm42U",
        "outputId": "623c7916-1001-404e-eab9-57e081334f63"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7298165751774%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRn8urH-nYs0",
        "outputId": "263d2e6e-5763-48fd-f700-ee6cf5d6a9c0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSu7i--SoqJ2",
        "outputId": "333cf6a8-3d0a-4616-bc0f-c9d5c8791e29"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6698432192843184, Val loss: 0.8144789776231489, Train Acc: 0.8809247522984914, Val Acc: 0.7355737046458696\n",
            "Epoch 2, Loss: 0.6692691474218994, Val loss: 0.8117450093611692, Train Acc: 0.8820405248594126, Val Acc: 0.7381175525505422\n",
            "Epoch 3, Loss: 0.6697060545625171, Val loss: 0.8118539253870646, Train Acc: 0.8830670356154602, Val Acc: 0.7378497790868925\n",
            "Epoch 4, Loss: 0.6668322959177175, Val loss: 0.809512092007531, Train Acc: 0.8840042845666339, Val Acc: 0.7403936269915652\n",
            "Epoch 5, Loss: 0.6667932681208663, Val loss: 0.8098944670114762, Train Acc: 0.8844505935910024, Val Acc: 0.7397241933324408\n",
            "Epoch 6, Loss: 0.666788195952391, Val loss: 0.8119235624614943, Train Acc: 0.8837811300544497, Val Acc: 0.7381175525505422\n",
            "Epoch 7, Loss: 0.6662869670791843, Val loss: 0.8113930551414816, Train Acc: 0.8848076408104972, Val Acc: 0.7389208729414914\n",
            "Epoch 8, Loss: 0.6660661182851872, Val loss: 0.8062684790700929, Train Acc: 0.8845398553958761, Val Acc: 0.7442763422144866\n",
            "Epoch 9, Loss: 0.6657951565889212, Val loss: 0.8168329056511577, Train Acc: 0.8851200571275551, Val Acc: 0.7342348373276208\n",
            "Epoch 10, Loss: 0.6669101176778136, Val loss: 0.8095045130476992, Train Acc: 0.8837364991520128, Val Acc: 0.7398580800642657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "-FnM1XzMotFd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkw0DfVnqoMs",
        "outputId": "c2fbc68a-508b-4ca3-ad47-f88b364a1c14"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anqFabG6qp0z",
        "outputId": "d53ed85f-69b2-4ae7-f167-c6b7208cf181"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6665451908722902, Val loss: 0.8118848759903867, Train Acc: 0.8846291172007498, Val Acc: 0.7389208729414914, LR: 0.0004509999999999993\n",
            "Epoch 2, Loss: 0.6666540765015149, Val loss: 0.8093777966295552, Train Acc: 0.8844505935910024, Val Acc: 0.7402597402597403, LR: 0.00010800000000000139\n",
            "Epoch 3, Loss: 0.6665853818936905, Val loss: 0.8123183989117289, Train Acc: 0.8854771043470498, Val Acc: 0.7370464586959432, LR: 0.0003530000000000014\n",
            "Epoch 4, Loss: 0.6656146260068627, Val loss: 0.8084941674501468, Train Acc: 0.8857002588592341, Val Acc: 0.7422680412371134, LR: 0.00020600000000000278\n",
            "Epoch 5, Loss: 0.6648004499935357, Val loss: 0.8089227890356993, Train Acc: 0.885744889761671, Val Acc: 0.7413308341143393, LR: 0.000255\n",
            "Epoch 6, Loss: 0.6644767205260078, Val loss: 0.8072329937902272, Train Acc: 0.8861019369811658, Val Acc: 0.7437407952871871, LR: 0.00030399999999999725\n",
            "Epoch 7, Loss: 0.6645389968513423, Val loss: 0.8104264410133035, Train Acc: 0.8859234133714183, Val Acc: 0.7411969473825144, LR: 0.00015700000000000558\n",
            "Epoch 8, Loss: 0.6645592113166113, Val loss: 0.8058147022866795, Train Acc: 0.8865482460055343, Val Acc: 0.7448118891417861, LR: 0.0004020000000000056\n",
            "Epoch 9, Loss: 0.6649759004258702, Val loss: 0.8088594145245023, Train Acc: 0.8864143532982237, Val Acc: 0.7413308341143393, LR: 5.900000000001114e-05\n",
            "Epoch 10, Loss: 0.6646468732771371, Val loss: 0.8095775924177251, Train Acc: 0.8861911987860395, Val Acc: 0.7406614004552149, LR: 0.0005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "ejhvBJxXqr1s"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md5pZmcAvdit",
        "outputId": "f74aeb63-e687-46f8-cc70-7506bff25abb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisLSTM(\n",
              "  (embedding): Embedding(1001, 64)\n",
              "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lCYONQAveXb",
        "outputId": "b39950c7-1b14-4a02-89e2-adaa7e815928"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6638745028748472, Val loss: 0.8097954499415863, Train Acc: 0.8866821387128447, Val Acc: 0.7411969473825144, LR: 0.00015400000000000036\n",
            "Epoch 2, Loss: 0.664317715201962, Val loss: 0.8128177161909577, Train Acc: 0.8865036151030974, Val Acc: 0.737314232159593, LR: 0.00020199999999999933\n",
            "Epoch 3, Loss: 0.6643301457421392, Val loss: 0.8113843982036297, Train Acc: 0.8862804605909131, Val Acc: 0.7387869862096667, LR: 5.8000000000000685e-05\n",
            "Epoch 4, Loss: 0.6643273663996292, Val loss: 0.8107897766634949, Train Acc: 0.8864589842006605, Val Acc: 0.7395903066006159, LR: 0.00010600000000000137\n",
            "Epoch 5, Loss: 0.6638226099842973, Val loss: 0.8086344951238388, Train Acc: 0.8864589842006605, Val Acc: 0.7421341545052885, LR: 0.00025\n",
            "Epoch 6, Loss: 0.6639648787995689, Val loss: 0.8080826004346212, Train Acc: 0.8870838168347764, Val Acc: 0.7422680412371134, LR: 0.00010600000000000137\n",
            "Epoch 7, Loss: 0.6635753313700358, Val loss: 0.8098220825195312, Train Acc: 0.8868160314201553, Val Acc: 0.7409291739188646, LR: 5.799999999999727e-05\n",
            "Epoch 8, Loss: 0.6645799131474943, Val loss: 0.8109932608074613, Train Acc: 0.8868606623225922, Val Acc: 0.7391886464051413, LR: 0.00020200000000000274\n",
            "Epoch 9, Loss: 0.6638269259719087, Val loss: 0.8107768393989302, Train Acc: 0.8872623404445238, Val Acc: 0.7387869862096667, LR: 0.00015399999999999865\n",
            "Epoch 10, Loss: 0.664380515572692, Val loss: 0.811364577876197, Train Acc: 0.8871284477372132, Val Acc: 0.7390547596733164, LR: 1e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional LSTM"
      ],
      "metadata": {
        "id": "8gxjRq-WxdQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentAnalysisBidirectionalLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pretrained_embedding):\n",
        "        super(SentimentAnalysisBidirectionalLSTM, self).__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_embedding, freeze=False)\n",
        "        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        lstm_out = self.layer_norm(lstm_out[:, -1, :])\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        h0 = torch.zeros((self.n_layers * 2, batch_size, self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.n_layers * 2, batch_size, self.hidden_dim)).to(device)\n",
        "        hidden = (h0, c0)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "Iw4k9QgkyO6C"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentAnalysisBidirectionalLSTMTemperature(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers, dropout, pretrained_embedding, init_temp=1.0):\n",
        "        super(SentimentAnalysisBidirectionalLSTMTemperature, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_embedding, freeze=False)\n",
        "        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, 3)\n",
        "\n",
        "        self.temperature = nn.Parameter(torch.ones(1) * init_temp)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        out = self.temperature_scale(out)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        h0 = torch.zeros((self.n_layers * 2, batch_size, self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.n_layers * 2, batch_size, self.hidden_dim)).to(device)\n",
        "        hidden = (h0, c0)\n",
        "        return hidden\n",
        "\n",
        "    def temperature_scale(self, logits):\n",
        "        temperature = self.temperature.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
        "        return logits / temperature"
      ],
      "metadata": {
        "id": "Lg2QM1yzHTqP"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = SentimentAnalysisBidirectionalLSTM(vocab_size=len(glove.stoi)+1, embedding_dim=100, hidden_dim=512, output_dim=3, n_layers=3, dropout=0.3, pretrained_embedding=embedding_matrix)\n",
        "new_model.to(device)\n",
        "\n",
        "print(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyjiP6B3ymjv",
        "outputId": "40e27749-bf58-4b48-d10c-51ecf83097b8"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentAnalysisBidirectionalLSTM(\n",
            "  (embedding): Embedding(400001, 100)\n",
            "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=1024, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional LSTM Training"
      ],
      "metadata": {
        "id": "Qu5llVOwzmL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "4jy4yxYeWVOD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_criterion = nn.CrossEntropyLoss()\n",
        "new_optimizer = torch.optim.Adam(new_model.parameters(), lr=0.0001, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "9jGgxrBa0JMX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0, path='new_model_weights.pth'):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "ZwqkNFkW4G3W"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_train_model(model, train_loader, val_loader, loss_function, optimizer, epochs, save_path):\n",
        "    '''\n",
        "    Trains the LSTM model on the training data.\n",
        "    '''\n",
        "\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=True, path=save_path)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_losses = []\n",
        "        train_acc = 0.0\n",
        "\n",
        "        # Sets model to training mode, enabling dropout and batch normalization\n",
        "        model.train()\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            batch_size = inputs.size(0)\n",
        "            h = model.init_hidden(batch_size=batch_size)\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            h = tuple([each.data for each in h])\n",
        "            # Reset gradients to prevent accumulation across batches\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs, h = model(inputs, h)\n",
        "\n",
        "            # Calculates loss by comparing outputs to targets\n",
        "            loss = loss_function(outputs, targets)\n",
        "\n",
        "            # Calculates gradient of loss to adjust weights efficiently\n",
        "            loss.backward()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            acc = accuracy(outputs, targets)\n",
        "            train_acc += acc\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "\n",
        "            # Updates weights based on calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation loop\n",
        "\n",
        "        val_losses = []\n",
        "        val_acc = 0.0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                val_batch_size = inputs.size(0)\n",
        "                val_h = model.init_hidden(batch_size=val_batch_size)\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "                outputs, val_h = model(inputs, val_h)\n",
        "                val_losses.append(loss_function(outputs, targets).item())\n",
        "                acc = accuracy(outputs, targets)\n",
        "                val_acc += acc\n",
        "\n",
        "\n",
        "        train_loss = np.mean(train_losses)\n",
        "        val_loss = np.mean(val_losses)\n",
        "        train_acc = train_acc/len(train_loader.dataset)\n",
        "        val_acc = val_acc/len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        current_lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "        early_stopping(val_loss, model)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        #current_lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {train_loss}, Val loss: {val_loss}, Train Acc: {train_acc}, Val Acc: {val_acc}, LR: {current_lr}')"
      ],
      "metadata": {
        "id": "wNQZhKLkzigO"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_model(new_model, train_loader, val_loader, new_criterion, new_optimizer, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF-DWFv9zAPG",
        "outputId": "6b1d1983-7f17-4dd3-cd98-2232b1ecebdf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (inf --> 0.910444).  Saving model ...\n",
            "Epoch 1, Loss: 1.0122419106654632, Val loss: 0.9104438658453461, Train Acc: 0.49477818441488886, Val Acc: 0.6229749631811488, LR: 0.0001\n",
            "Validation loss decreased (0.910444 --> 0.885483).  Saving model ...\n",
            "Epoch 2, Loss: 0.9048006495519242, Val loss: 0.8854826428951361, Train Acc: 0.6310363295545836, Val Acc: 0.6512250635961976, LR: 0.0001\n",
            "Validation loss decreased (0.885483 --> 0.876820).  Saving model ...\n",
            "Epoch 3, Loss: 0.8776701247250592, Val loss: 0.8768196335205665, Train Acc: 0.6622779612603766, Val Acc: 0.6599277011648146, LR: 0.0001\n",
            "Validation loss decreased (0.876820 --> 0.865991).  Saving model ...\n",
            "Epoch 4, Loss: 0.8615651307282625, Val loss: 0.8659909826058608, Train Acc: 0.6807105239667947, Val Acc: 0.6718436202972285, LR: 0.0001\n",
            "Validation loss decreased (0.865991 --> 0.847314).  Saving model ...\n",
            "Epoch 5, Loss: 0.8469936774666832, Val loss: 0.8473140322245084, Train Acc: 0.6955726144782648, Val Acc: 0.6935332708528584, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 6, Loss: 0.8357220263223023, Val loss: 0.857094562970675, Train Acc: 0.7105239667946086, Val Acc: 0.6857678404070157, LR: 0.0001\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 7, Loss: 0.8249084185331296, Val loss: 0.8509762602993566, Train Acc: 0.7195394090868518, Val Acc: 0.6903199892890615, LR: 0.0001\n",
            "Validation loss decreased (0.847314 --> 0.837725).  Saving model ...\n",
            "Epoch 8, Loss: 0.816006303003371, Val loss: 0.8377248614262311, Train Acc: 0.7290011604034634, Val Acc: 0.7069219440353461, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 9, Loss: 0.8057167193828485, Val loss: 0.8434886473875779, Train Acc: 0.739935731500491, Val Acc: 0.7007631543714018, LR: 0.0001\n",
            "Validation loss decreased (0.837725 --> 0.827686).  Saving model ...\n",
            "Epoch 10, Loss: 0.8016695864180214, Val loss: 0.8276861203022492, Train Acc: 0.7464964741587075, Val Acc: 0.7188378631677601, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 11, Loss: 0.7940564682001402, Val loss: 0.838646600389073, Train Acc: 0.7526109077925556, Val Acc: 0.7053153032534476, LR: 0.0001\n",
            "Validation loss decreased (0.827686 --> 0.821911).  Saving model ...\n",
            "Epoch 12, Loss: 0.7873625970973588, Val loss: 0.8219107903985896, Train Acc: 0.760376684816567, Val Acc: 0.7233900120498059, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 13, Loss: 0.7816997929516002, Val loss: 0.8223769328533075, Train Acc: 0.7661787021333571, Val Acc: 0.7244611059044048, LR: 0.0001\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 14, Loss: 0.7748569774831462, Val loss: 0.8260660553589846, Train Acc: 0.7738998482549317, Val Acc: 0.720980050876958, LR: 0.0001\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 15, Loss: 0.7712726042820857, Val loss: 0.8333818673068641, Train Acc: 0.7778273676693743, Val Acc: 0.713482393894765, LR: 5e-05\n",
            "Validation loss decreased (0.821911 --> 0.812861).  Saving model ...\n",
            "Epoch 16, Loss: 0.7577515504299066, Val loss: 0.812861186826331, Train Acc: 0.7923324109613497, Val Acc: 0.7342348373276208, LR: 5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 17, Loss: 0.7545710037916135, Val loss: 0.8130327218618149, Train Acc: 0.796304561278229, Val Acc: 0.7334315169366715, LR: 5e-05\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 18, Loss: 0.7521439002789663, Val loss: 0.8164810818484706, Train Acc: 0.7986699991073819, Val Acc: 0.729682688445575, LR: 5e-05\n",
            "Validation loss decreased (0.812861 --> 0.811698).  Saving model ...\n",
            "Epoch 19, Loss: 0.7502859941235295, Val loss: 0.8116981575631688, Train Acc: 0.7991609390341873, Val Acc: 0.7367786852322935, LR: 5e-05\n",
            "Validation loss decreased (0.811698 --> 0.809181).  Saving model ...\n",
            "Epoch 20, Loss: 0.7474897532721191, Val loss: 0.8091806387289976, Train Acc: 0.8040703383022405, Val Acc: 0.7379836658187173, LR: 5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 21, Loss: 0.7436074585656495, Val loss: 0.8148704802888072, Train Acc: 0.806837454253325, Val Acc: 0.7330298567411969, LR: 5e-05\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 22, Loss: 0.7417939335871966, Val loss: 0.813414343401917, Train Acc: 0.8081317504239935, Val Acc: 0.7335654036684964, LR: 5e-05\n",
            "Validation loss decreased (0.809181 --> 0.807071).  Saving model ...\n",
            "Epoch 23, Loss: 0.7408309142474095, Val loss: 0.8070706067941128, Train Acc: 0.8110773899848255, Val Acc: 0.7424019279689382, LR: 5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 24, Loss: 0.7380449768484827, Val loss: 0.8103610929260906, Train Acc: 0.8121485316433098, Val Acc: 0.7389208729414914, LR: 5e-05\n",
            "Validation loss decreased (0.807071 --> 0.806327).  Saving model ...\n",
            "Epoch 25, Loss: 0.7371194129995471, Val loss: 0.8063270887757978, Train Acc: 0.8134428278139784, Val Acc: 0.7428035881644129, LR: 5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 26, Loss: 0.7327844991303577, Val loss: 0.8063413786073016, Train Acc: 0.8187539052039632, Val Acc: 0.7417324943098139, LR: 5e-05\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 27, Loss: 0.7363387747028275, Val loss: 0.8078307412628435, Train Acc: 0.8143800767651522, Val Acc: 0.7414647208461641, LR: 5e-05\n",
            "Validation loss decreased (0.806327 --> 0.804401).  Saving model ...\n",
            "Epoch 28, Loss: 0.7326218901876032, Val loss: 0.8044008821503729, Train Acc: 0.8190216906185843, Val Acc: 0.7444102289463114, LR: 5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 29, Loss: 0.7285436891083025, Val loss: 0.8111042135801071, Train Acc: 0.8219673301794163, Val Acc: 0.7377158923550676, LR: 5e-05\n",
            "Validation loss decreased (0.804401 --> 0.804350).  Saving model ...\n",
            "Epoch 30, Loss: 0.7280980010657568, Val loss: 0.8043501142762665, Train Acc: 0.8230831027403374, Val Acc: 0.7434730218235373, LR: 5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 31, Loss: 0.7271012833655051, Val loss: 0.8047450016706418, Train Acc: 0.824377398911006, Val Acc: 0.7432052483598875, LR: 2.5e-05\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 32, Loss: 0.721744804810255, Val loss: 0.8044164471137218, Train Acc: 0.8294653217888066, Val Acc: 0.7434730218235373, LR: 2.5e-05\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 33, Loss: 0.7218519493385598, Val loss: 0.8088755597416152, Train Acc: 0.8306257252521646, Val Acc: 0.7398580800642657, LR: 2.5e-05\n",
            "Validation loss decreased (0.804350 --> 0.803116).  Saving model ...\n",
            "Epoch 34, Loss: 0.7200405711462016, Val loss: 0.803115814160078, Train Acc: 0.8310274033740962, Val Acc: 0.7460168697282099, LR: 2.5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 35, Loss: 0.7200616497939129, Val loss: 0.8065399517360915, Train Acc: 0.8316076051057752, Val Acc: 0.742669701432588, LR: 2.5e-05\n",
            "Validation loss decreased (0.803116 --> 0.801936).  Saving model ...\n",
            "Epoch 36, Loss: 0.7182604697694805, Val loss: 0.8019355830983219, Train Acc: 0.8335267339105596, Val Acc: 0.7472218503146338, LR: 2.5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 37, Loss: 0.7183811864961586, Val loss: 0.8024390156452472, Train Acc: 0.8334821030081229, Val Acc: 0.746954076850984, LR: 2.5e-05\n",
            "Validation loss decreased (0.801936 --> 0.801117).  Saving model ...\n",
            "Epoch 38, Loss: 0.7182487108428933, Val loss: 0.8011173244215485, Train Acc: 0.8337498884227439, Val Acc: 0.7472218503146338, LR: 2.5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 39, Loss: 0.7166330433978654, Val loss: 0.8041120416078812, Train Acc: 0.834597875569044, Val Acc: 0.7453474360690856, LR: 2.5e-05\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 40, Loss: 0.7168190959851626, Val loss: 0.8038385021380889, Train Acc: 0.8358475408372757, Val Acc: 0.7454813228009104, LR: 2.5e-05\n",
            "Validation loss decreased (0.801117 --> 0.801088).  Saving model ...\n",
            "Epoch 41, Loss: 0.7158838355982745, Val loss: 0.8010877299512553, Train Acc: 0.8360260644470231, Val Acc: 0.748025170705583, LR: 1.25e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 42, Loss: 0.7145865778637748, Val loss: 0.8047181867126726, Train Acc: 0.8379451932518075, Val Acc: 0.7436069085553622, LR: 1.25e-05\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 43, Loss: 0.7131024833418366, Val loss: 0.8018948950319209, Train Acc: 0.8382129786664286, Val Acc: 0.7464185299236845, LR: 1.25e-05\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 44, Loss: 0.7133547726519767, Val loss: 0.8042509678082589, Train Acc: 0.838123716861555, Val Acc: 0.7449457758736109, LR: 6.25e-06\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 45, Loss: 0.7124248761736769, Val loss: 0.8016874296033484, Train Acc: 0.8388824422029814, Val Acc: 0.7476235105101084, LR: 6.25e-06\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.load_state_dict(torch.load('3layer_model_weights.pth'))\n",
        "new_model.eval()\n",
        "new_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRG5Rx7A3btF",
        "outputId": "6b352fda-0f64-4e2f-ee57-a9c3f6ecf477"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisBidirectionalLSTM(\n",
              "  (embedding): Embedding(400001, 100)\n",
              "  (lstm): LSTM(100, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rms_op = optim.RMSprop(new_model.parameters(), lr=0.001, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "as_D7BbJ82cw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_model(new_model, train_loader, val_loader, new_criterion, rms_op, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDSxL8Oz3jDp",
        "outputId": "91d39d47-651a-439b-ad19-a4e0a48b421a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (inf --> 1.121291).  Saving model ...\n",
            "Epoch 1, Loss: 1.112818504500593, Val loss: 1.1212914142853174, Train Acc: 0.3386592876907971, Val Acc: 0.3266836256526978, LR: 0.001\n",
            "Validation loss decreased (1.121291 --> 1.031243).  Saving model ...\n",
            "Epoch 2, Loss: 1.064477282202142, Val loss: 1.0312425774386806, Train Acc: 0.4189056502722485, Val Acc: 0.4840005355469273, LR: 0.001\n",
            "Validation loss decreased (1.031243 --> 0.921721).  Saving model ...\n",
            "Epoch 3, Loss: 0.920417710077389, Val loss: 0.9217212388658116, Train Acc: 0.6222886726769615, Val Acc: 0.6023564064801178, LR: 0.001\n",
            "Validation loss decreased (0.921721 --> 0.822969).  Saving model ...\n",
            "Epoch 4, Loss: 0.8290781319311201, Val loss: 0.8229689455439901, Train Acc: 0.715968936891904, Val Acc: 0.72432721917258, LR: 0.001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 5, Loss: 0.7913407357329996, Val loss: 0.8410340058497894, Train Acc: 0.7570293671338034, Val Acc: 0.7037086624715491, LR: 0.001\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 6, Loss: 0.7797247974621264, Val loss: 0.8920639483337729, Train Acc: 0.7691689725966259, Val Acc: 0.6628732092649618, LR: 0.001\n",
            "Validation loss decreased (0.822969 --> 0.807473).  Saving model ...\n",
            "Epoch 7, Loss: 0.7697739210563508, Val loss: 0.8074725091966808, Train Acc: 0.7797464964741587, Val Acc: 0.7387869862096667, LR: 0.001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 8, Loss: 0.7648127498450102, Val loss: 0.8168019224435855, Train Acc: 0.7848344193519593, Val Acc: 0.7300843486410497, LR: 0.001\n",
            "Validation loss decreased (0.807473 --> 0.802561).  Saving model ...\n",
            "Epoch 9, Loss: 0.7562170291897917, Val loss: 0.8025613819432055, Train Acc: 0.7931803981076497, Val Acc: 0.7460168697282099, LR: 0.001\n",
            "Validation loss decreased (0.802561 --> 0.798839).  Saving model ...\n",
            "Epoch 10, Loss: 0.7495956262971601, Val loss: 0.7988393311826592, Train Acc: 0.7988038918146925, Val Acc: 0.7498995849511313, LR: 0.001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 11, Loss: 0.7459076255814642, Val loss: 0.8072624558057541, Train Acc: 0.8032223511559404, Val Acc: 0.74052751372339, LR: 0.001\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 12, Loss: 0.7458453660676961, Val loss: 0.8155684858305842, Train Acc: 0.803891814692493, Val Acc: 0.7314232159592984, LR: 0.001\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 13, Loss: 0.7448242092743899, Val loss: 0.8125239773693248, Train Acc: 0.8047398018387932, Val Acc: 0.7359753648413442, LR: 0.0005\n",
            "Validation loss decreased (0.798839 --> 0.796333).  Saving model ...\n",
            "Epoch 14, Loss: 0.7244896404763572, Val loss: 0.7963331194005461, Train Acc: 0.825537802374364, Val Acc: 0.7519078859285044, LR: 0.0005\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 15, Loss: 0.7170658906300863, Val loss: 0.8009293558251145, Train Acc: 0.8329911630813175, Val Acc: 0.7474896237782835, LR: 0.0005\n",
            "Validation loss decreased (0.796333 --> 0.794425).  Saving model ...\n",
            "Epoch 16, Loss: 0.7152803220979849, Val loss: 0.7944252251559852, Train Acc: 0.8355351245202178, Val Acc: 0.7555228276877761, LR: 0.0005\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 17, Loss: 0.7155464067418351, Val loss: 0.796057772432637, Train Acc: 0.8345086137641703, Val Acc: 0.7529789797831035, LR: 0.0005\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 18, Loss: 0.7167685981150027, Val loss: 0.795546229578491, Train Acc: 0.833125055788628, Val Acc: 0.7525773195876289, LR: 0.0005\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 19, Loss: 0.7126825068071697, Val loss: 0.801580895216037, Train Acc: 0.8385253949834865, Val Acc: 0.7472218503146338, LR: 0.00025\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 20, Loss: 0.7048309183867908, Val loss: 0.8009452305288396, Train Acc: 0.8465143265196823, Val Acc: 0.7476235105101084, LR: 0.00025\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_model(new_model, train_loader, val_loader, new_criterion, rms_op, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-aWboXwACZA",
        "outputId": "2ced3eb3-3226-41e7-85d2-f08df044a9fe"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (inf --> 0.794534).  Saving model ...\n",
            "Epoch 1, Loss: 0.7042513265568986, Val loss: 0.7945339822361612, Train Acc: 0.8468267428367402, Val Acc: 0.7555228276877761, LR: 0.00025\n",
            "Validation loss decreased (0.794534 --> 0.794215).  Saving model ...\n",
            "Epoch 2, Loss: 0.7048900894969278, Val loss: 0.7942154229196727, Train Acc: 0.8465589574221191, Val Acc: 0.7555228276877761, LR: 0.00025\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 3, Loss: 0.7052089237419629, Val loss: 0.7944183217154609, Train Acc: 0.8464250647148085, Val Acc: 0.7555228276877761, LR: 0.00025\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 4, Loss: 0.7042024709560253, Val loss: 0.7943591750585116, Train Acc: 0.846291172007498, Val Acc: 0.7555228276877761, LR: 0.00025\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 5, Loss: 0.7050907589771129, Val loss: 0.7942574263637902, Train Acc: 0.8458448629831296, Val Acc: 0.7555228276877761, LR: 0.000125\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 6, Loss: 0.7046721074995492, Val loss: 0.7944797654437203, Train Acc: 0.8461126483977506, Val Acc: 0.7555228276877761, LR: 0.000125\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adamw = optim.AdamW(new_model.parameters(), lr=0.0001, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "Lnynx2yeAn6D"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.load_state_dict(torch.load('3layer_model_weights.pth'))\n",
        "new_model.eval()\n",
        "new_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkltYVpQA4zY",
        "outputId": "80a6366e-816d-4519-84c2-afa2f242d585"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisBidirectionalLSTM(\n",
              "  (embedding): Embedding(400001, 100)\n",
              "  (lstm): LSTM(100, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_model(new_model, train_loader, val_loader, new_criterion, adamw, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXpAF__zA2Qe",
        "outputId": "cd904bbf-b1a2-4be1-d964-5ce99be618db"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (inf --> 0.906626).  Saving model ...\n",
            "Epoch 1, Loss: 0.9801121860148221, Val loss: 0.9066262881979983, Train Acc: 0.5367312327055253, Val Acc: 0.6281965457223189, LR: 0.0001\n",
            "Validation loss decreased (0.906626 --> 0.892452).  Saving model ...\n",
            "Epoch 2, Loss: 0.8948431140676862, Val loss: 0.8924523291424808, Train Acc: 0.6429527805052219, Val Acc: 0.6433257464185299, LR: 0.0001\n",
            "Validation loss decreased (0.892452 --> 0.870765).  Saving model ...\n",
            "Epoch 3, Loss: 0.8715909002852915, Val loss: 0.8707654292766864, Train Acc: 0.6703115236990091, Val Acc: 0.6710402999062793, LR: 0.0001\n",
            "Validation loss decreased (0.870765 --> 0.852961).  Saving model ...\n",
            "Epoch 4, Loss: 0.8545254504578745, Val loss: 0.8529609553834312, Train Acc: 0.6878514683566902, Val Acc: 0.6907216494845361, LR: 0.0001\n",
            "Validation loss decreased (0.852961 --> 0.852841).  Saving model ...\n",
            "Epoch 5, Loss: 0.839814794369233, Val loss: 0.852840706323966, Train Acc: 0.7037400696242078, Val Acc: 0.6892488954344624, LR: 0.0001\n",
            "Validation loss decreased (0.852841 --> 0.850408).  Saving model ...\n",
            "Epoch 6, Loss: 0.8287893470875558, Val loss: 0.8504076513469728, Train Acc: 0.7158796750870302, Val Acc: 0.6909894229481859, LR: 0.0001\n",
            "Validation loss decreased (0.850408 --> 0.836199).  Saving model ...\n",
            "Epoch 7, Loss: 0.8176801707330252, Val loss: 0.8361987359503396, Train Acc: 0.7278853878425422, Val Acc: 0.707993037889945, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 8, Loss: 0.8126072346994341, Val loss: 0.8377448106423403, Train Acc: 0.7318129072569848, Val Acc: 0.7051814165216227, LR: 0.0001\n",
            "Validation loss decreased (0.836199 --> 0.832947).  Saving model ...\n",
            "Epoch 9, Loss: 0.8018698327222101, Val loss: 0.8329470162717705, Train Acc: 0.7438186200124967, Val Acc: 0.7126790735038158, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 10, Loss: 0.795786930285288, Val loss: 0.8361065372442588, Train Acc: 0.75042399357315, Val Acc: 0.7097335654036685, LR: 0.0001\n",
            "Validation loss decreased (0.832947 --> 0.830427).  Saving model ...\n",
            "Epoch 11, Loss: 0.7891324418902057, Val loss: 0.830426615018111, Train Acc: 0.758055877889851, Val Acc: 0.715624581603963, LR: 0.0001\n",
            "Validation loss decreased (0.830427 --> 0.820840).  Saving model ...\n",
            "Epoch 12, Loss: 0.7833116248122647, Val loss: 0.820839671497671, Train Acc: 0.764482727840757, Val Acc: 0.7247288793680546, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 13, Loss: 0.7749089386388447, Val loss: 0.8224586696706266, Train Acc: 0.7728287065964474, Val Acc: 0.7227205783906815, LR: 0.0001\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 14, Loss: 0.7700444780863248, Val loss: 0.8407883343533573, Train Acc: 0.7782290457913059, Val Acc: 0.7035747757397242, LR: 0.0001\n",
            "Validation loss decreased (0.820840 --> 0.817533).  Saving model ...\n",
            "Epoch 15, Loss: 0.767204894978776, Val loss: 0.8175328654101771, Train Acc: 0.7805944836204588, Val Acc: 0.7276743874682019, LR: 0.0001\n",
            "Validation loss decreased (0.817533 --> 0.815202).  Saving model ...\n",
            "Epoch 16, Loss: 0.7630204648373813, Val loss: 0.8152024165177957, Train Acc: 0.7855485137909488, Val Acc: 0.7322265363502477, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 17, Loss: 0.7596049977843239, Val loss: 0.8160298950651772, Train Acc: 0.7892528786932071, Val Acc: 0.7318248761547731, LR: 0.0001\n",
            "Validation loss decreased (0.815202 --> 0.810712).  Saving model ...\n",
            "Epoch 18, Loss: 0.7519215447270972, Val loss: 0.8107122381528219, Train Acc: 0.7966616084977238, Val Acc: 0.7371803454277681, LR: 0.0001\n",
            "Validation loss decreased (0.810712 --> 0.805763).  Saving model ...\n",
            "Epoch 19, Loss: 0.7485393978591658, Val loss: 0.8057634264994891, Train Acc: 0.8011246987414086, Val Acc: 0.7420002677734636, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 20, Loss: 0.748301214641995, Val loss: 0.8125206496980455, Train Acc: 0.800990806034098, Val Acc: 0.733967063863971, LR: 0.0001\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 21, Loss: 0.7460860238116012, Val loss: 0.8170162948787721, Train Acc: 0.8034008747656878, Val Acc: 0.730887669031999, LR: 0.0001\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 22, Loss: 0.740622855659224, Val loss: 0.8066852912943587, Train Acc: 0.8092921538873517, Val Acc: 0.7425358147007631, LR: 5e-05\n",
            "Validation loss decreased (0.805763 --> 0.805344).  Saving model ...\n",
            "Epoch 23, Loss: 0.7300227371036497, Val loss: 0.8053438052152976, Train Acc: 0.820851557618495, Val Acc: 0.7425358147007631, LR: 5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 24, Loss: 0.7246330823653784, Val loss: 0.8263546921249129, Train Acc: 0.8251361242524324, Val Acc: 0.7212478243406079, LR: 5e-05\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 25, Loss: 0.7261969314681159, Val loss: 0.8101920480402107, Train Acc: 0.8237079353744533, Val Acc: 0.7387869862096667, LR: 5e-05\n",
            "Validation loss decreased (0.805344 --> 0.801338).  Saving model ...\n",
            "Epoch 26, Loss: 0.7225209673245748, Val loss: 0.8013381958007812, Train Acc: 0.8277693474962063, Val Acc: 0.7474896237782835, LR: 5e-05\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 27, Loss: 0.721697799330763, Val loss: 0.8028445157230409, Train Acc: 0.8289743818620012, Val Acc: 0.7460168697282099, LR: 5e-05\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 28, Loss: 0.7183360661196913, Val loss: 0.8022008222392482, Train Acc: 0.8325002231545122, Val Acc: 0.746954076850984, LR: 5e-05\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 29, Loss: 0.718145241764536, Val loss: 0.8030832078721788, Train Acc: 0.8329019012764438, Val Acc: 0.7461507564600348, LR: 2.5e-05\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 30, Loss: 0.7122148474057516, Val loss: 0.8023204849316523, Train Acc: 0.8379005623493707, Val Acc: 0.7465524166555094, LR: 2.5e-05\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_a = test_accuracy(new_model, test_loader)\n",
        "print(f'Test accuracy: {new_a}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABLqF1-v9HR9",
        "outputId": "759e2b16-0bf9-49a1-c532-dcc4d95f2383"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7424019279689382%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_model = SentimentAnalysisBidirectionalLSTMTemperature(embedding_dim=100, hidden_dim=256, n_layers=2, dropout=0.5, pretrained_embedding=embedding_matrix, init_temp=10.0)\n",
        "og_model.load_state_dict(torch.load('og_model_weights.pth'))\n",
        "og_model.eval()\n",
        "og_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "RD3rcBy1-Mck",
        "outputId": "d4cf8bec-96f9-4445-9606-676fd9097f60"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for SentimentAnalysisBidirectionalLSTMTemperature:\n\tMissing key(s) in state_dict: \"temperature\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-187-7b51adc3d9d5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mog_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentAnalysisBidirectionalLSTMTemperature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mog_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'og_model_weights.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mog_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mog_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2189\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2190\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SentimentAnalysisBidirectionalLSTMTemperature:\n\tMissing key(s) in state_dict: \"temperature\". "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_accuracy = test_accuracy(og_model, test_loader)\n",
        "print(f'Test accuracy: {og_accuracy}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3eYJnNqHBH3",
        "outputId": "2f69ff1a-39b0-4cc6-e4ee-1dd8d6594ff6"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7723925558977105%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adamw_new = optim.AdamW(og_model.parameters(), lr=0.0001, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "72JJd3cXIsLF"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_model(og_model, train_loader, val_loader, new_criterion, adamw_new, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWGHqwgZHomy",
        "outputId": "19007236-e20f-4644-c763-07c2f8e5a2d9"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (inf --> 0.774746).  Saving model ...\n",
            "Epoch 1, Loss: 0.6603527087771315, Val loss: 0.774746024201059, Train Acc: 0.8911898598589664, Val Acc: 0.7748025170705584, LR: 0.0001\n",
            "Validation loss decreased (0.774746 --> 0.773510).  Saving model ...\n",
            "Epoch 2, Loss: 0.6584096763208721, Val loss: 0.7735103592913375, Train Acc: 0.892751941444256, Val Acc: 0.7773463649752309, LR: 0.0001\n",
            "Validation loss decreased (0.773510 --> 0.773236).  Saving model ...\n",
            "Epoch 3, Loss: 0.657673509032638, Val loss: 0.7732355431613759, Train Acc: 0.8935106667856824, Val Acc: 0.7770785915115812, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 4, Loss: 0.6582735603691167, Val loss: 0.7777041324183472, Train Acc: 0.8934660358832456, Val Acc: 0.7717231222385862, LR: 0.0001\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 5, Loss: 0.6554310471244008, Val loss: 0.7739541148528074, Train Acc: 0.8954744264929037, Val Acc: 0.7753380639978578, LR: 0.0001\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 6, Loss: 0.6547861282642071, Val loss: 0.7752400764033326, Train Acc: 0.8966794608586985, Val Acc: 0.7735975364841344, LR: 5e-05\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 7, Loss: 0.6534261348580364, Val loss: 0.7751951085196601, Train Acc: 0.8976167098098724, Val Acc: 0.7745347436069085, LR: 5e-05\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rms = optim.RMSprop(og_model.parameters(), lr=0.001, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "VrEdG9-BHx-E"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_model(og_model, train_loader, val_loader, new_criterion, rms, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_roXPtpOJWQo",
        "outputId": "1bb2e9f9-e0db-4154-baa7-54274ea58677"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (inf --> 0.795469).  Saving model ...\n",
            "Epoch 1, Loss: 0.748583139856996, Val loss: 0.7954685932550675, Train Acc: 0.7997857716683031, Val Acc: 0.7508367920739055, LR: 0.001\n",
            "Validation loss decreased (0.795469 --> 0.787891).  Saving model ...\n",
            "Epoch 2, Loss: 0.7100483299660207, Val loss: 0.7878909452348692, Train Acc: 0.8403552619833973, Val Acc: 0.7592716561788727, LR: 0.001\n",
            "Validation loss decreased (0.787891 --> 0.785771).  Saving model ...\n",
            "Epoch 3, Loss: 0.6953856710694793, Val loss: 0.7857711916295891, Train Acc: 0.8554851379094885, Val Acc: 0.7634221448654438, LR: 0.001\n",
            "Validation loss decreased (0.785771 --> 0.781650).  Saving model ...\n",
            "Epoch 4, Loss: 0.6883425286352804, Val loss: 0.781649687860766, Train Acc: 0.8621351423725788, Val Acc: 0.7666354264292409, LR: 0.001\n",
            "Validation loss decreased (0.781650 --> 0.779821).  Saving model ...\n",
            "Epoch 5, Loss: 0.6869596647061513, Val loss: 0.7798211324928154, Train Acc: 0.8637864857627421, Val Acc: 0.7681081804793145, LR: 0.001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 6, Loss: 0.6815120565925229, Val loss: 0.7817727913204421, Train Acc: 0.8686512541283585, Val Acc: 0.7650287856473423, LR: 0.001\n",
            "Validation loss decreased (0.779821 --> 0.777848).  Saving model ...\n",
            "Epoch 7, Loss: 0.6779457458064088, Val loss: 0.7778484148856921, Train Acc: 0.8730697134696064, Val Acc: 0.771857008970411, LR: 0.001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 8, Loss: 0.6791196526625217, Val loss: 0.7812228192630996, Train Acc: 0.8718646791038115, Val Acc: 0.7674387468201901, LR: 0.001\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 9, Loss: 0.6768663877095932, Val loss: 0.7818990899966314, Train Acc: 0.8739623315183433, Val Acc: 0.7674387468201901, LR: 0.001\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 10, Loss: 0.6771981303508465, Val loss: 0.7871381054576646, Train Acc: 0.8737838079085959, Val Acc: 0.7623510510108448, LR: 0.0005\n",
            "Validation loss decreased (0.777848 --> 0.776196).  Saving model ...\n",
            "Epoch 11, Loss: 0.6654902528493832, Val loss: 0.7761960982257484, Train Acc: 0.8859680442738552, Val Acc: 0.77292810282501, LR: 0.0005\n",
            "Validation loss decreased (0.776196 --> 0.774239).  Saving model ...\n",
            "Epoch 12, Loss: 0.6603791307859611, Val loss: 0.7742393037192842, Train Acc: 0.8909220744443452, Val Acc: 0.7745347436069085, LR: 0.0005\n",
            "Validation loss decreased (0.774239 --> 0.772775).  Saving model ...\n",
            "Epoch 13, Loss: 0.6602590085774066, Val loss: 0.7727747289543478, Train Acc: 0.8908774435419085, Val Acc: 0.7768108180479314, LR: 0.0005\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 14, Loss: 0.6604275316254705, Val loss: 0.777092509290092, Train Acc: 0.8906096581272873, Val Acc: 0.7723925558977105, LR: 0.0005\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 15, Loss: 0.6622224265014344, Val loss: 0.7744772383290478, Train Acc: 0.8896277782736767, Val Acc: 0.7750702905342081, LR: 0.0005\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 16, Loss: 0.6601921878648959, Val loss: 0.783874011447287, Train Acc: 0.8907435508345979, Val Acc: 0.7651626723791672, LR: 0.00025\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 17, Loss: 0.6550356046087042, Val loss: 0.7749284658676538, Train Acc: 0.8960099973221458, Val Acc: 0.7750702905342081, LR: 0.00025\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_accuracy = test_accuracy(og_model, test_loader)\n",
        "print(f'Test accuracy: {og_accuracy}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgPaMmBCJXen",
        "outputId": "4a8e6064-ecce-4bf7-a06f-3117c18bd255"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7678404070156647%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_model.load_state_dict(torch.load('og_model_weights.pth'))\n",
        "og_model.eval()\n",
        "og_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1gRC5kQKf1i",
        "outputId": "3f48d3df-9d1f-4725-b4d8-38072bdd7087"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisBidirectionalLSTMNoLayerNorm(\n",
              "  (embedding): Embedding(400001, 100)\n",
              "  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_accuracy = test_accuracy(og_model, test_loader)\n",
        "print(f'Test accuracy: {og_accuracy}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXtkadi2M3bd",
        "outputId": "cbdf86bd-516b-4790-a2b3-681647b31f90"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7808274200026777%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_model = SentimentAnalysisBidirectionalLSTMTemperature(embedding_dim=100, hidden_dim=256, n_layers=2, dropout=0.5, pretrained_embedding=embedding_matrix, init_temp=7.0)\n",
        "combined_model.load_state_dict(torch.load('combined_model_weights.pth'))\n",
        "combined_model.eval()\n",
        "combined_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fcct45WTdVe",
        "outputId": "b729c0d8-6cf8-4023-94a3-4fc7388e44f4"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentAnalysisBidirectionalLSTMTemperature(\n",
              "  (embedding): Embedding(400001, 100)\n",
              "  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_adamw = optim.AdamW(combined_model.parameters(), lr=0.0001, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "hMgei31iZB53"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_model(combined_model, train_loader, val_loader, new_criterion, combined_adamw, 30, save_path='combined_model_weights.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VF62_KMY46j",
        "outputId": "bdca6a36-84b2-4f11-9f05-c9a4f8f6292d"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (inf --> 0.611076).  Saving model ...\n",
            "Epoch 1, Loss: 0.41502265254316845, Val loss: 0.6110764662934165, Train Acc: 0.8686066232259216, Val Acc: 0.7753380639978578, LR: 0.0001\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 2, Loss: 0.40136276062397536, Val loss: 0.6504401444879353, Train Acc: 0.8736052842988485, Val Acc: 0.7670370866247155, LR: 0.0001\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 3, Loss: 0.38580093959457856, Val loss: 0.6253903225446359, Train Acc: 0.8815049540301705, Val Acc: 0.7754719507296827, LR: 0.0001\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 4, Loss: 0.37391697507128757, Val loss: 0.635681670700383, Train Acc: 0.8852985807373025, Val Acc: 0.7746686303387335, LR: 5e-05\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 5, Loss: 0.3507584372901509, Val loss: 0.631828465522864, Train Acc: 0.8950281174685352, Val Acc: 0.7713214620431116, LR: 5e-05\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_accuracy = test_accuracy(combined_model, test_loader)\n",
        "print(f'Test accuracy: {combined_accuracy}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBtuL6RAZl9m",
        "outputId": "a39ff152-6647-4df7-e945-46fd8a824fed"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7761413843888071%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Scoring"
      ],
      "metadata": {
        "id": "cyUJyWiBNCNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text, model):\n",
        "    words = [preprocess(word) for word in text.lower().split()[:15]]\n",
        "    word_indices = [glove.stoi[word] if word in glove.stoi else 0 for word in words]\n",
        "\n",
        "    if len(word_indices) < 15:\n",
        "        word_indices.extend([0] * (15 - len(word_indices)))\n",
        "\n",
        "    inputs = torch.tensor(word_indices).unsqueeze(0).to(device)\n",
        "\n",
        "    batch_size = inputs.size(0)\n",
        "    h = model.init_hidden(batch_size)\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output, h = model(inputs, h)\n",
        "        prediction = torch.softmax(output, dim=1).cpu().numpy()\n",
        "\n",
        "    label_mapping = {2: 'Positive', 1: 'Neutral', 0: 'Negative'}\n",
        "    predicted_class = label_mapping[np.argmax(prediction)]\n",
        "    predicted_probabilities = prediction[0][np.argmax(prediction)]\n",
        "\n",
        "    return predicted_class, predicted_probabilities"
      ],
      "metadata": {
        "id": "pKHJ98XpNGUY"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.random.randint(0, 20000, 10)\n",
        "for index in indices:\n",
        "    print(df_resampled['headline'][index])\n",
        "    print('-'*10)\n",
        "    print(f'Actual sentiment is: {df_resampled[\"label\"][index]}')\n",
        "    print('-'*10)\n",
        "    pred_class, pred_prob = predict_text(df['headline'][index], combined_model)\n",
        "    print(f\"Predicted sentiment is '{pred_class}' with a probability of {pred_prob}\")\n",
        "    print('='*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lsxyeNZNePb",
        "outputId": "8d05d0ec-c8d0-4f2c-ad09-779aece3711e"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meme stocks: GameStop, AMC decline in intraday trading\n",
            "----------\n",
            "Actual sentiment is: Negative\n",
            "----------\n",
            "Predicted sentiment is 'Negative' with a probability of 0.9679281115531921\n",
            "================================================================================\n",
            "McCormick (MKC) Q1 Earnings and Revenues Top Estimates\n",
            "----------\n",
            "Actual sentiment is: Positive\n",
            "----------\n",
            "Predicted sentiment is 'Positive' with a probability of 0.8916739225387573\n",
            "================================================================================\n",
            "Earnings Beat: Whitbread plc Just Beat Analyst Forecasts, And Analysts Have Been Updating Their Models\n",
            "----------\n",
            "Actual sentiment is: Positive\n",
            "----------\n",
            "Predicted sentiment is 'Positive' with a probability of 0.9283627867698669\n",
            "================================================================================\n",
            "Why is it Wise to Hold Host Hotels (HST) Stock in Your Portfolio?\n",
            "----------\n",
            "Actual sentiment is: Neutral\n",
            "----------\n",
            "Predicted sentiment is 'Neutral' with a probability of 0.7174232602119446\n",
            "================================================================================\n",
            "Macy's (M) Omni-Channel Efforts Bode Well, Up 60% in a Year\n",
            "----------\n",
            "Actual sentiment is: Positive\n",
            "----------\n",
            "Predicted sentiment is 'Positive' with a probability of 0.9159680008888245\n",
            "================================================================================\n",
            "Marriott presses pause on all Russia development\n",
            "----------\n",
            "Actual sentiment is: Negative\n",
            "----------\n",
            "Predicted sentiment is 'Negative' with a probability of 0.9700167775154114\n",
            "================================================================================\n",
            "West Receives Exhibitor Award at INTERPHEX 2022 for Proprietary DeltaCube Modeling Platform\n",
            "----------\n",
            "Actual sentiment is: Positive\n",
            "----------\n",
            "Predicted sentiment is 'Positive' with a probability of 0.8645333051681519\n",
            "================================================================================\n",
            "Alliant Energy (LNT) to Post Q4 Earnings: What's in Store?\n",
            "----------\n",
            "Actual sentiment is: Neutral\n",
            "----------\n",
            "Predicted sentiment is 'Neutral' with a probability of 0.9477609992027283\n",
            "================================================================================\n",
            "CEO Talk From Elon Musk and Jamie Dimon\n",
            "----------\n",
            "Actual sentiment is: Neutral\n",
            "----------\n",
            "Predicted sentiment is 'Negative' with a probability of 0.7327119708061218\n",
            "================================================================================\n",
            "Blackbaud (BLKB) Q1 Earnings Miss Estimates\n",
            "----------\n",
            "Actual sentiment is: Negative\n",
            "----------\n",
            "Predicted sentiment is 'Negative' with a probability of 0.9506193399429321\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rGuXJ6RuNzSf"
      },
      "execution_count": 161,
      "outputs": []
    }
  ]
}
